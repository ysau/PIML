{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysau/PIML/blob/main/one_dimensional_harmonics_oscillator_forward_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1D Harmonics Oscillator: Forward Problem"
      ],
      "metadata": {
        "id": "tUHNl3iEdEfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement\n",
        "A mass on spring can be described by the Ordinary Differential Equation (ODE)\n",
        "\n",
        "$$\n",
        "m \\dfrac{d^2 x}{d t^2} + \\mu \\dfrac{d x}{d t} + kx = 0~,\n",
        "$$\n",
        "with the initial conditions\n",
        "$$\n",
        "x(0) = 1~~,~~\\dfrac{d x}{d t} = 0~.\n",
        "$$\n",
        "\n",
        "We are going to train a neural network NN to approximate the solution of the ODE\n",
        "\n",
        "$$\n",
        "N\\!N(t;\\theta) \\approx u(t)~,\n",
        "$$\n",
        "\n",
        "with the loss function L\n",
        "\n",
        "$$\n",
        "L(\\theta)= (N\\!N(0;\\theta) - 1)^2 + \\lambda_1 \\left(\\frac{d N\\!N}{dt}(0;\\theta) - 0\\right)^2 + \\frac{\\lambda_2}{N} \\sum^{N}_{i} \\left( \\left[ m\\frac{d^2}{dt^2} + \\mu \\frac{d}{dt} + k \\right] N\\!N(t_{i};\\theta) Â \\right)^2 + \\frac{\\lambda}{M} \\sum^{M}_{j} \\left( N\\!N(t_{j};\\theta) - u_{\\mathrm{obs}}(t_{j})Â \\right)^2\n",
        "$$\n",
        "\n",
        "The first two terms are the boundary conditions, the third term is the Physics loss, and the last term is the data loss"
      ],
      "metadata": {
        "id": "WQQqAgs1evDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Codes\n",
        "from PIL import Image as PILImage\n",
        "from IPython.display import display, Image as DisplayImage\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from enum import Enum, auto\n",
        "\n",
        "# Problem Constants\n",
        "# Physics constants\n",
        "DELTA = 2\n",
        "W0 = 20\n",
        "X_MIN = 0\n",
        "X_MAX = 1\n",
        "# Training constants\n",
        "NUM_TRAIN_POINTS = 30\n",
        "NUM_TRAIN_STEPS = 50000\n",
        "LEARNING_RATE = 1e-4\n",
        "PHYSICS_SCLAE = 1e-4\n",
        "LOG_EVERY = 150\n",
        "\n",
        "def oscillator(d, w0, x):\n",
        "    \"\"\"Defines the analytical solution to the 1D underdamped harmonic oscillator problem.\n",
        "    Equations taken from: https://beltoforion.de/en/harmonic_oscillator/\"\"\"\n",
        "    assert d < w0\n",
        "    w = np.sqrt(w0**2-d**2)\n",
        "    phi = np.arctan(-d/w)\n",
        "    A = 1/(2*np.cos(phi))\n",
        "    cos = torch.cos(phi+w*x)\n",
        "    sin = torch.sin(phi+w*x)\n",
        "    exp = torch.exp(-d*x)\n",
        "    y  = exp*2*A*cos\n",
        "    return y\n",
        "\n",
        "class FCN(nn.Module):\n",
        "    \"Defines a connected network\"\n",
        "\n",
        "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
        "        super().__init__()\n",
        "        activation = nn.Tanh\n",
        "        self.fcs = nn.Sequential(*[\n",
        "                        nn.Linear(N_INPUT, N_HIDDEN),\n",
        "                        activation()])\n",
        "        self.fch = nn.Sequential(*[\n",
        "                        nn.Sequential(*[\n",
        "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
        "                            activation()]) for _ in range(N_LAYERS-1)])\n",
        "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fcs(x)\n",
        "        x = self.fch(x)\n",
        "        x = self.fce(x)\n",
        "        return x\n",
        "\n",
        "def generate_train_data(delta, w0, num_points, x_min=0, x_max=1):\n",
        "  x = x = torch.linspace(x_min,x_max,num_points).view(-1,1).detach().requires_grad_(True)\n",
        "  y = oscillator(delta, w0, x).view(-1,1).clone().detach().requires_grad_(True)\n",
        "  return x, y\n",
        "\n",
        "def plot_result(x,y,x_data,y_data,yh,xp=None,step=0,title=\"PINN Results\"):\n",
        "    \"Pretty plot training results\"\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(x,y, color=\"grey\", linewidth=2, alpha=0.8, label=\"Exact solution\")\n",
        "    plt.plot(x,yh, color=\"tab:blue\", linewidth=4, alpha=0.8, label=\"Neural network prediction\")\n",
        "    plt.scatter(x_data, y_data, s=60, color=\"tab:orange\", alpha=0.4, label='Training data')\n",
        "    if xp is not None:\n",
        "        plt.scatter(xp, -0*torch.ones_like(xp), s=60, color=\"tab:green\", alpha=0.4,\n",
        "                    label='Physics loss training locations')\n",
        "    l = plt.legend(loc=(1.01,0.34), frameon=False, fontsize=\"large\")\n",
        "    plt.setp(l.get_texts(), color=\"k\")\n",
        "    plt.xlim(-0.05, 1.05)\n",
        "    plt.ylim(-1.1, 1.1)\n",
        "    plt.text(1.065,0.7,\"Training step: %step\"%(step+1),fontsize=\"xx-large\",color=\"k\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "def save_gif_PIL(outfile, files, fps=5, loop=0):\n",
        "    \"Helper function for saving GIFs\"\n",
        "    imgs = [PILImage.open(file) for file in files]\n",
        "    imgs[0].save(fp=outfile, format='GIF', append_images=imgs[1:], save_all=True, duration=int(1000/fps), loop=loop)\n",
        "\n",
        "\n",
        "class TrainType(Enum):\n",
        "    ALL = auto()\n",
        "    DATA = auto()\n",
        "    PHYSICS = auto()\n",
        "\n",
        "def train(delta, w0, num_train_points, num_train_steps, train_type):\n",
        "  if train_type == TrainType.PHYSICS:\n",
        "    # Using the first train point as boundary conditions\n",
        "    x_train, y_train = generate_train_data(delta, w0, num_points=1, x_min=X_MIN, x_max=X_MAX / 2)\n",
        "    # Note that y coordinate is discarded\n",
        "    x_physics, _ = generate_train_data(delta, w0, num_points=num_train_points, x_min=X_MIN, x_max=X_MAX)\n",
        "\n",
        "  # Full-domain resolution for plotting\n",
        "  x_ref = torch.linspace(0,1,1000).view(-1,1)\n",
        "  y_ref = oscillator(delta, w0, x_ref)\n",
        "\n",
        "  torch.manual_seed(123)\n",
        "  model = FCN(1,1,32,3)\n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "\n",
        "  plot_files = []\n",
        "\n",
        "  for step in range(1, num_train_steps + 1):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # compute the \"boundary loss\"\n",
        "    y_hat_boundary = model(x_train)\n",
        "    boundary_value_loss = (y_hat_boundary - y_train).pow(2).mean()\n",
        "    dy_dx_boundary = torch.autograd.grad(y_hat_boundary.sum(), x_train, create_graph=True)[0]\n",
        "    boundary_loss = boundary_value_loss + dy_dx_boundary.pow(2).mean()\n",
        "\n",
        "    # compute the \"physics loss\"\n",
        "    y_hat_phys = model(x_physics)\n",
        "    dy_dx_phys  = torch.autograd.grad(y_hat_phys.sum(), x_physics, create_graph=True)[0]\n",
        "    d2y_d2x_phys = torch.autograd.grad(dy_dx_phys.sum(),  x_physics,  create_graph=True)[0]\n",
        "    mu, k = 2 * delta, w0**2\n",
        "    residual = d2y_d2x_phys + mu * dy_dx_phys + k * y_hat_phys\n",
        "    physics_loss = PHYSICS_SCLAE * residual.pow(2).mean()\n",
        "\n",
        "    # backpropagate joint loss\n",
        "    loss = physics_loss + boundary_loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    # plot the result as training progresses\n",
        "    if step % LOG_EVERY == 0:\n",
        "        with torch.no_grad():\n",
        "          y_hat_ref = model(x_ref)\n",
        "          if train_type == TrainType.PHYSICS:\n",
        "            plot_title = \"Physics Loss Only\"\n",
        "            fname = f\"pinn_physics_{step:08d}.png\"\n",
        "          elif train_type == TrainType.DATA:\n",
        "            plot_title = \"Data Loss Only\"\n",
        "            fname = f\"pinn_data_{step:08d}.png\"\n",
        "          else:\n",
        "            plot_title = \"Physics + Data Loss\"\n",
        "            fname = f\"pinn_physics_data_{step:08d}.png\"\n",
        "          plot_result(x_ref,y_ref,x_train.detach()[:num_train_points],y_train.detach()[:num_train_points], y_hat_ref.detach(), x_physics.detach(), step,\n",
        "                      title=plot_title)\n",
        "          plt.savefig(fname, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
        "          plot_files.append(fname)\n",
        "          if (step+1) % 6000 == 0: plt.show()\n",
        "          else: plt.close(\"all\")\n",
        "  try:\n",
        "      if train_type == TrainType.PHYSICS:\n",
        "          fname = \"pinn_physics.gif\"\n",
        "      save_gif_PIL(fname, plot_files, fps=20, loop=0)\n",
        "      display(DisplayImage(filename=fname))\n",
        "  except Exception as e:\n",
        "      print(f\"GIF creation skipped: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def check_gpu():\n",
        "  if torch.cuda.is_available():\n",
        "    print(f\"{torch.cuda.device_count()} GPU(s) are available\")\n",
        "  else:\n",
        "    print(\"GPU is not available. Using CPU\")"
      ],
      "metadata": {
        "id": "JQJdUO40dAaP",
        "cellView": "form"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check Compute Resource\n",
        "check_gpu()"
      ],
      "metadata": {
        "id": "U9kpw-tFl84o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cec0eb5-1225-484d-dec1-7c998d0f8f06"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is not available. Using CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training using Physics Loss Only\n",
        "train(DELTA, W0, NUM_TRAIN_POINTS, NUM_TRAIN_STEPS, TrainType.PHYSICS)"
      ],
      "metadata": {
        "id": "VNzFkvmimCEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [Optional] Install Black Code Formatter - Require connection to Google Drive\n",
        "!pip install black[jupyter] --quiet\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "l74UX16Ijgs8",
        "outputId": "9cde6bc9-9bde-43e3-f3be-5efceb79f58d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Format using Black\n",
        "!black /content/drive/MyDrive/'Colab Notebooks'/'one_dimensional_harmonics_oscillator_forward_problem.ipynb'"
      ],
      "metadata": {
        "id": "mbAhEqm1h4SK",
        "outputId": "5ca8e097-feee-4107-9b70-aacfab6b239f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mreformatted /content/drive/MyDrive/Colab Notebooks/one_dimensional_harmonics_oscillator_forward_problem.ipynb\u001b[0m\n",
            "\n",
            "\u001b[1mAll done! âœ¨ ðŸ° âœ¨\u001b[0m\n",
            "\u001b[34m\u001b[1m1 file \u001b[0m\u001b[1mreformatted\u001b[0m.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Disclaimers\n",
        "This notebook was modified based on\n",
        "\n",
        "\n",
        "1.   https://github.com/benmoseley/harmonic-oscillator-pinn\n",
        "2.   https://github.com/benmoseley/FBPINNs\n",
        "\n",
        "My specific contributions include\n",
        "\n",
        "\n",
        "1.   Separate the effects of Physics loss vs data loss\n",
        "2.   Incorporate boundary loss\n",
        "3.   How to improve training using Physics loss only via scheduled training\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1h8yuYokdMpO"
      }
    }
  ]
}